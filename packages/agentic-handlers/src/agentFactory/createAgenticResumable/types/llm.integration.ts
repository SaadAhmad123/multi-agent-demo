import type { Span } from '@opentelemetry/api';
import type { z } from 'zod';
import type { AgenticMessageContent, AgenticToolDefinition } from '../../AgentRunner/types.js';

/** Input parameters for calling an agentic LLM service. */
export type LLMIntegrationParam = {
  /**
   * Indicates the conversation phase and expected LLM behavior.
   * - 'init': Starting a new conversation or processing a user message
   * - 'tool_results': Processing the results of previously requested tool executions
   */
  type: 'init' | 'tool_results';
  /** Complete conversation for the LLM to process */
  messages: {
    role: 'user' | 'assistant';
    content: AgenticMessageContent[];
  }[];
  /** Formatted tool definitions available to the LLM. */
  toolDefinitions: AgenticToolDefinition[];
  /** OpenTelemetry span for logging and tracing LLM operations */
  span: Span;
  /**
   * [Optional] Structured output format constraint.
   * When provided, the LLM must return a JSON object matching this schema
   * instead of a plain text response. Useful for extracting structured data.
   */
  outputFormat: z.AnyZodObject | null;
  /** System prompt to guide the LLM's behavior and tool usage patterns */
  systemPrompt: string | null;
  currentToolInteractionCount: number;
};

/**
 * Response from an agentic LLM service call.
 *
 * The LLM can either provide a direct response or request tool executions,
 * but not both simultaneously.
 */
export type LLMIntegrationOutput = {
  /**
   * Tool execution requests generated by the LLM.
   * Each request is typed according to its Arvo contract, ensuring the
   * request data matches the expected service input schema. Null when
   * the LLM provides a direct response instead of requesting tools.
   */
  toolRequests: Array<{
    type: string;
    data: object;
    id: string;
  }> | null;
  /**
   * Direct response from the LLM.
   * Can be a string for text responses or an object when outputFormat
   * is specified. Must be null when toolRequests are present.
   */
  response: string | object | null;
  /** Aggregated count of tool requests by type. */
  toolTypeCount: Record<string, number>;
  /**
   * Optional token usage statistics from the LLM provider.
   * Helps with cost tracking and performance monitoring.
   */
  usage?: {
    tokens: {
      prompt: number;
      completion: number;
    };
  };
};

/**
 * Function signature every LLM integration must implement.
 * Given conversation context, available tool definitions, and optional
 * structured-output constraints, the integration must return either:
 * 1. A set of tool requests (`toolRequests`) when the LLM decides external
 *    actions are required, or
 * 2. A direct `response` (text or structured object) when no tools are needed.
 * Implementations should ensure mutual exclusivity between `toolRequests`
 * and `response` (i.e., one is `null` while the other is populated).
 */
export type LLMIntergration = (param: LLMIntegrationParam) => Promise<LLMIntegrationOutput>;

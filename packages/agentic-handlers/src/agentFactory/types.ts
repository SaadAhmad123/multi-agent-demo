import type { InferVersionedArvoContract } from 'arvo-core';
import type { Span } from '@opentelemetry/api';
import type { VersionedArvoContract } from 'arvo-core';
import type { z } from 'zod';
import type {
  AgenticMessageContentSchema,
  AgenticTextMessageContentSchema,
  AgenticToolCallMessageContentSchema,
  AgenticToolResultMessageContentSchema,
} from './schemas.js';

/**
 * Generic type alias for any versioned Arvo contract.
 * Used as a constraint for service contract type parameters.
 */
// biome-ignore lint/suspicious/noExplicitAny: Needs to be general
export type AnyVersionedContract = VersionedArvoContract<any, any>;

/**
 * Message content representing the result of a completed tool execution.
 *
 * Contains the output data from a tool that was previously invoked by the LLM.
 * The content is JSON-serialized and linked back to the original request via tool_use_id.
 */
export type AgenticToolResultMessageContent = z.infer<typeof AgenticToolResultMessageContentSchema>;

/**
 * Message content representing a request to execute a specific tool.
 *
 * Generated by LLMs when they determine that external tool execution is required
 * to fulfill a user request. Contains the tool name and all necessary parameters
 * for execution according to the tool's Arvo contract schema.
 */
export type AgenticToolCallMessageContent = z.infer<typeof AgenticToolCallMessageContentSchema>;

/**
 * Message content containing plain text communication.
 *
 * Represents standard conversational text without any tool interactions.
 * Used for both user messages and direct LLM responses that don't require tools.
 */
export type AgenticTextMessageContent = z.infer<typeof AgenticTextMessageContentSchema>;

/**
 * Union type for all possible message content formats in agentic conversations.
 * Supports text messages, tool execution requests, and tool result responses.
 */
export type AgenticMessageContent = z.infer<typeof AgenticMessageContentSchema>;

/**
 * Tool definition format expected by LLM services.
 *
 * Simplified representation of an Arvo service contract that provides
 * the LLM with the necessary information to understand and invoke tools.
 */
export type AgenticToolDefinition = {
  /** The name/identifier of the tool (maps to Arvo contract event type) */
  name: string;
  /** Human-readable description of what the tool does and when to use it */
  description: string;
  /** JSON schema defining the expected input parameters for the tool */
  input_schema: object;
};

/**
 * Input parameters for calling an agentic LLM service.
 *
 * Provides the LLM with conversation context, available tools, and configuration
 * needed to generate appropriate responses or tool execution requests. Supports
 * both conversation initialization and processing of tool execution results.
 */
export type CallAgenticLLMParam<
  TServices extends Record<string, AnyVersionedContract> = Record<string, AnyVersionedContract>,
  TOutput extends z.AnyZodObject = z.AnyZodObject,
> = {
  /**
   * Indicates the conversation phase and expected LLM behavior.
   * - 'init': Starting a new conversation or processing a user message
   * - 'tool_results': Processing the results of previously requested tool executions
   */
  type: 'init' | 'tool_results';

  /**
   * Complete conversation history in chronological order.
   */
  messages: {
    role: 'user' | 'assistant';
    content: AgenticMessageContent[];
  }[];

  /**
   * Formatted tool definitions available to the LLM.
   *
   * These are derived from the service contracts and pre-formatted for
   * LLM consumption. Use the 'services' field to access original contracts
   * for type-safe tool parameter validation.
   */
  toolDefinitions: AgenticToolDefinition[];

  /**
   * Available Arvo service contracts that the LLM can invoke as tools.
   */
  services: TServices;

  /** OpenTelemetry span for logging and tracing LLM operations */
  span: Span;

  /**
   * [Optional] Structured output format constraint.
   *
   * When provided, the LLM must return a JSON object matching this schema
   * instead of a plain text response. Useful for extracting structured data.
   */
  outputFormat: TOutput | null;

  /** System prompt to guide the LLM's behavior and tool usage patterns */
  systemPrompt: string | null;
};

/**
 * Response from an agentic LLM service call.
 *
 * The LLM can either provide a direct response or request tool executions,
 * but not both simultaneously. Tool requests are fully typed according to
 * their corresponding Arvo contracts for type-safe execution.
 */
export type CallAgenticLLMOutput<
  TServices extends Record<string, AnyVersionedContract> = Record<string, AnyVersionedContract>,
> = {
  /**
   * Tool execution requests generated by the LLM.
   *
   * Each request is typed according to its Arvo contract, ensuring the
   * request data matches the expected service input schema. Null when
   * the LLM provides a direct response instead of requesting tools.
   */
  toolRequests: Array<
    {
      [K in keyof TServices]: {
        type: InferVersionedArvoContract<TServices[K]>['accepts']['type'];
        data: InferVersionedArvoContract<TServices[K]>['accepts']['data'];
        id: string;
      };
    }[keyof TServices]
  > | null;

  /**
   * Direct response from the LLM.
   *
   * Can be a string for text responses or an object when outputFormat
   * is specified. Must be null when toolRequests are present.
   */
  response: string | object | null;

  /**
   * Aggregated count of tool requests by type.
   */
  toolTypeCount: Record<string, number>;

  /**
   * Optional token usage statistics from the LLM provider.
   * Helps with cost tracking and performance monitoring.
   */
  usage?: {
    tokens: {
      prompt: number;
      completion: number;
    };
  };
};

/**
 * Function signature for calling an agentic LLM service.
 *
 * Implementations should process the conversation context and tool definitions
 * to generate either direct responses or structured tool execution requests.
 * Must handle both conversation initialization and tool result processing.
 */
export type CallAgenticLLM<
  TServices extends Record<string, AnyVersionedContract> = Record<string, AnyVersionedContract>,
  TOutput extends z.AnyZodObject = z.AnyZodObject,
> = (param: CallAgenticLLMParam<TServices, TOutput>) => Promise<CallAgenticLLMOutput<TServices>>;

/**
 * Configuration parameters for creating an agentic resumable orchestrator.
 *
 * Defines all components needed to create an AI agent that can maintain
 * conversations, make intelligent tool decisions, and execute complex workflows
 * through Arvo's event-driven architecture. Supports both simple chat and
 * structured data extraction scenarios.
 */
export type CreateAgenticResumableParams<
  TName extends string,
  TServices extends Record<string, AnyVersionedContract> = Record<string, AnyVersionedContract>,
  TOutput extends z.AnyZodObject = z.AnyZodObject,
> = {
  /**
   * Unique identifier for this agent instance.
   *
   * Used in Arvo contract URIs, event type, and agent identification
   * across the system system.
   */
  name: TName;

  /**
   * The agent description. This becomes a part of the
   * contract generated by the factory
   */
  description?: string;

  /**
   * LLM service integration function.
   *
   * Handles the actual communication with the LLM provider (OpenAI, Anthropic, etc.)
   * and implements the conversation and tool request logic.
   */
  agenticLLMCaller: CallAgenticLLM<TServices, TOutput>;

  /**
   * Optional structured output format specification.
   *
   * When provided, constrains the agent to return data matching this Zod schema
   * instead of free-form text responses. Useful for data extraction workflows.
   */
  outputFormat?: TOutput;

  /**
   * Available Arvo service contracts for tool execution.
   *
   * Each contract defines a service the LLM can invoke, providing full
   * type safety and automatic schema validation for tool parameters and responses.
   */
  services?: TServices;

  /**
   * Optional domain routing configuration for service execution.
   */
  serviceDomains?: Partial<
    {
      [K in keyof TServices]: {
        [T in TServices[K]['accepts']['type']]: string[];
      };
    }[keyof TServices]
  >;

  /**
   * Dynamic system prompt generation function.
   *
   * Receives conversation context and available tools to generate contextually
   * appropriate system prompts for different conversation phases (init vs tool_results).
   */
  systemPrompt?: (
    param: Pick<CallAgenticLLMParam<TServices, TOutput>, 'messages' | 'services' | 'toolDefinitions' | 'type'>,
  ) => string;

  /**
   * Whether to include conversation history in orchestrator responses.
   *
   * When enabled, the orchestrator will return the complete message history
   * along with the final response, useful for debugging and conversation tracking.
   */
  enableMessageHistoryInResponse?: boolean;

  /**
   * Maximum number of times the LLM is allowed to perform tool calls.
   * Default is 5 times
   */
  maxToolInteractions?: number;
};
